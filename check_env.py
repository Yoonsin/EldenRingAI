from EldenEnv import EldenEnv
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback
import os
import tensorflow as tf  # parry_detector í˜¸í™˜ì„ ìœ„í•´ í•„ìš”

logdir = r"C:\GitHub\EldenRingAI\log"
model_path = "ppo_episode_model"
env = EldenEnv(logdir)
max_models_to_keep = 10  # ìµœì‹  ëª¨ë¸ 10ê°œ ìœ ì§€

# âœ”ï¸ ì½œë°±: ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ì €ì¥, ìµœê·¼ 10ê°œë§Œ ìœ ì§€
class SaveRecentEpisodesCallback(BaseCallback):
    def __init__(self, save_path, max_keep=10, verbose=1):
        super().__init__(verbose)
        self.save_path = save_path
        self.max_keep = max_keep
        self.episode_num = 0
        self.saved_eps = []

    def _on_step(self) -> bool:
        if self.locals.get("dones", [False])[0]:
            self.episode_num += 1
            path = f"{self.save_path}_ep{self.episode_num}.zip"
            self.model.save(path)
            self.saved_eps.append(self.episode_num)
            if self.verbose > 0:
                print(f"[ğŸ’¾] ì—í”¼ì†Œë“œ {self.episode_num} ì¢…ë£Œ í›„ ëª¨ë¸ ì €ì¥ë¨: {path}")

            # ìµœëŒ€ ëª¨ë¸ ê°œìˆ˜ ì´ˆê³¼ ì‹œ ì‚­ì œ
            while len(self.saved_eps) > self.max_keep:
                old_ep = self.saved_eps.pop(0)
                old_path = f"{self.save_path}_ep{old_ep}.zip"
                if os.path.exists(old_path):
                    os.remove(old_path)
                    if self.verbose > 0:
                        print(f"[ğŸ—‘ï¸] ì˜¤ë˜ëœ ëª¨ë¸ ì‚­ì œë¨: {old_path}")
        return True

# âœ”ï¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ìƒˆë¡œ ë§Œë“¤ê¸°
if os.path.exists(model_path + "_ep1.zip"):
    latest_ep = 1
    while os.path.exists(f"{model_path}_ep{latest_ep + 1}.zip"):
        latest_ep += 1
    latest_model_path = f"{model_path}_ep{latest_ep}.zip"
    print(f"[âœ”] ì—í”¼ì†Œë“œ {latest_ep} ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    model = PPO.load(latest_model_path, env=env)

    # ğŸ” ë§ˆì§€ë§‰ ëª¨ë¸ì„ ep1ë¡œ ë®ì–´ì“°ê¸°
    ep1_model_path = f"{model_path}_ep1.zip"
    model.save(ep1_model_path)
    print(f"[ğŸ”] {latest_model_path} â†’ {ep1_model_path} ë¡œ ì´ˆê¸°í™” ì €ì¥ ì™„ë£Œ")

    # ğŸ—‘ï¸ ep1 ì œì™¸í•˜ê³  ëª¨ë‘ ì‚­ì œ
    for ep in range(2, latest_ep + 1):
        old_model_path = f"{model_path}_ep{ep}.zip"
        if os.path.exists(old_model_path):
            os.remove(old_model_path)
            print(f"[ğŸ—‘ï¸] ì‚­ì œë¨: {old_model_path}")
else:
    print("[ğŸ†•] ìƒˆ PPO ëª¨ë¸ ìƒì„±")
    model = PPO("MlpPolicy", env, verbose=1, tensorboard_log="./ppo_logs")

# âœ”ï¸ í•™ìŠµ ì‹œì‘
callback = SaveRecentEpisodesCallback(save_path=model_path, max_keep=max_models_to_keep)
model.learn(total_timesteps=100_000, callback=callback)

print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")